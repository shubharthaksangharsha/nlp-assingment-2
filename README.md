# NLP Knowledge Base ğŸ“š

A comprehensive collection of NLP questions, answers, and insights organized by different categorization schemes. This project provides a web interface to explore and search through curated NLP-related content from Stack Exchange.

by [**Shubharthak**](https://shubharthaksangharsha.github.io/)

[![Web Demo](web-app/static/img/top_tags.png)](https://nlp-assignment.duckdns.org/)

> ğŸ”— [**Live Demo**](https://nlp-assignment.duckdns.org/) | [**Documentation**](src/README.md) | [**Web App**](web-app/README.md)

---

## âœ¨ Features

### ğŸ“Š Multiple Categorization Schemes
- **Task-based**: Text Classification, Sentiment Analysis, etc.
- **Keyword-based**: Implementation Issues, Library Usage, etc.
- **Library-based**: NLTK, spaCy, BERT, etc.
- **Question Type**: How, What, Why, etc.

### ğŸ“ Rich Content
- ğŸ” Curated questions and answers
- ğŸ’» Code examples
- ğŸ› ï¸ Implementation details
- âœ… Best practices
- â— Common issues and solutions

### ğŸŒ Modern Web Interface
- ğŸ¨ Clean and responsive design
- ğŸ§­ Easy navigation
- ğŸ“‚ Category browsing
- ğŸ” Search functionality
- ğŸŒ“ Dark/Light mode toggle

---

## ğŸ“Š Insights

<div align="center">
  <img src="web-app/static/img/description_wordcloud.png" alt="Description Word Cloud" width="400"/>
  <p><em>Word Cloud of NLP Topics</em></p>
</div>

---

## ğŸ—‚ï¸ Project Structure

```
nlp_knowledge_base/
â”œâ”€â”€ ğŸ“ src/                
â”‚   â”œâ”€â”€ ğŸ“œ data_collector.py   
â”‚   â”œâ”€â”€ ğŸ“œ preprocessor.py     
â”‚   â”œâ”€â”€ ğŸ“œ data_visualizer.py  
â”‚   â”œâ”€â”€ ğŸ“œ categorizer.py      
â”‚   â””â”€â”€ ğŸ“œ main.py             
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ ğŸ“ categories/     # Processed data files
â”‚       â”œâ”€â”€ ğŸ“ keyword_based/
â”‚       â”œâ”€â”€ ğŸ“ task_based/
â”‚       â”œâ”€â”€ ğŸ“ library_based/
â”‚       â””â”€â”€ ğŸ“ question_type/
â”œâ”€â”€ ğŸ“ web-app/           # Web application
â”‚   â”œâ”€â”€ ğŸ“œ app.py         # Flask application
â”‚   â”œâ”€â”€ ğŸ“ static/        # Static assets
â”‚   â””â”€â”€ ğŸ“ templates/     # HTML templates
â”œâ”€â”€ ğŸ“œ vercel.json       # Vercel deployment config
â””â”€â”€ ğŸ“œ requirements.txt  # Python dependencies
```

## ğŸš€ Getting Started

### âš ï¸ IMPORTANT: Dataset Setup
You **MUST** download and unzip the dataset before running the application:

1. **Download the dataset** from the link below:
   [ğŸ”½ Click here to download the dataset](https://drive.google.com/file/d/1EPZ6mJvLAj0sJqNAWWLo8Bz90K2sSBgy/view?usp=sharing)

2. **Unzip the dataset** in the project root directory:
   ```bash
   unzip data.zip
   ```
   This will create the required `data/` folder with all necessary files.

### Running the Application

3. **Clone the Repository**
   ```bash
   git clone https://github.com/shubharthaksangharsha/nlp-assingment-2.git
   cd nlp-assingment-2
   ```

4. **Run the Application**
   - On Linux/Mac:
     ```bash
     ./run.sh
     ```
   - On Windows:
     ```bash
     run.bat
     ```
   
   The script will:
   - Create a virtual environment and install dependencies
   - Run the processing pipeline (skipping data collection)
   - Start the web application automatically

5. **Access the Web Interface**
   - Open your browser and navigate to `http://localhost:5000`

--- 

## ğŸ“¦ Dataset Details

The dataset contains pre-processed NLP questions and answers from Stack Exchange, organized into multiple categorization schemes.

âš ï¸ Note: Large raw .csv files are excluded from Git using .gitignore. The application requires the dataset to function properly.

## ğŸ“Š Data Organization

<div align="center">
  <img src="web-app/static/img/title_wordcloud.png" alt="Title Word Cloud" width="400"/>
  <p><em>Popular Topics in Questions</em></p>
</div>

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Stack Exchange community for valuable content
- Contributors and maintainers
- Open source NLP community 
