### NLP Knowledge Base - Source Code

> ğŸš€ The data pipeline that powers the NLP Knowledge Base project, transforming raw Stack Exchange data into organized, categorized knowledge.

[![Pipeline Status](https://img.shields.io/badge/pipeline-active-success.svg)](https://github.com/shubharthaksangharsha/nlp-knowledge-base)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## ğŸ—ºï¸ Directory Structure

```
src/
â”œâ”€â”€ ğŸ“¥ data_collector.py    # Stack Exchange API integration
â”œâ”€â”€ ğŸ§¹ preprocessor.py      # Data cleaning and text preprocessing
â”œâ”€â”€ ğŸ“Š data_visualizer.py   # Visualization generation
â”œâ”€â”€ ğŸ·ï¸ categorizer.py       # Post categorization logic
â”œâ”€â”€ ğŸ¯ main.py             # Pipeline orchestration
â””â”€â”€ ğŸ“¦ __init__.py         # Package initialization
```

## ğŸ”¨ Components

### 1. ğŸ“¥ Data Collection (`data_collector.py`)
- ğŸ”Œ Integrates with Stack Exchange API
- ğŸ“¡ Fetches NLP-related Q&A
- âš¡ Smart rate limiting and pagination
- ğŸ”„ Incremental updates support

### 2. ğŸ§¹ Data Preprocessing (`preprocessor.py`)
- ğŸ§¼ Text cleaning and normalization
- ğŸ”§ HTML entity handling
- ğŸ’» Code block preservation
- ğŸ“ Content standardization

### 3. ğŸ“Š Data Visualization (`data_visualizer.py`)
- ğŸ“ˆ Trend analysis and insights
- ğŸ¨ Interactive visualizations
- ğŸ” Pattern discovery
- ğŸ“‰ Usage statistics

### 4. ğŸ·ï¸ Categorization (`categorizer.py`)
- ğŸ¯ Multi-scheme categorization
- ğŸ¤– Intelligent category assignment
- ğŸ“‘ Content organization
- ğŸ”„ Dynamic rule updates

### 5. ğŸ¯ Pipeline Orchestration (`main.py`)
- ğŸ”„ End-to-end workflow
- ğŸ“ Comprehensive logging
- âš ï¸ Error handling
- ğŸ” Progress monitoring

## ğŸš€ Usage

### Complete Pipeline

```bash
# Run the entire pipeline
python main.py --config config.yaml
```

### Individual Components

```python
from src.data_collector import StackExchangeCollector
from src.preprocessor import DataPreprocessor
from src.categorizer import PostCategorizer
from src.data_visualizer import DataVisualizer

# Collect data
collector = StackExchangeCollector()
raw_data = collector.fetch_data()

# Process and categorize
preprocessor = DataPreprocessor()
categorizer = PostCategorizer()
clean_data = preprocessor.process(raw_data)
categorized_data = categorizer.categorize(clean_data)

# Generate visualizations
visualizer = DataVisualizer()
visualizer.generate_insights(categorized_data)
```

## ğŸ“Š Data Flow

```mermaid
graph LR
    A[Stack Exchange API] -->|Fetch| B[Data Collection]
    B -->|Raw Data| C[Preprocessing]
    C -->|Clean Data| D[Categorization]
    D -->|Organized Data| E[Visualization]
    E -->|Insights| F[Web Interface]
```

## âš™ï¸ Configuration

### Environment Variables
```bash
STACK_EXCHANGE_API_KEY=your_api_key
MAX_REQUESTS_PER_MINUTE=30
LOG_LEVEL=INFO
```

### Category Rules
```yaml
categories:
  task_based:
    - text_classification
    - sentiment_analysis
  library_based:
    - nltk
    - spacy
    - transformers
```

## ğŸ“¦ Output

The pipeline generates:
- ğŸ“„ JSON/CSV files with categorized posts
- ğŸ“Š Visualization assets for web interface
- ğŸ“ˆ Statistics and metadata
- ğŸ“ Processing logs

## ğŸ” Monitoring

- ğŸ“Š Progress tracking via logging
- âš ï¸ Error notifications
- ğŸ“ˆ Performance metrics
- ğŸ”„ Status updates

## ğŸ¤ Contributing

See our [Contributing Guide](../CONTRIBUTING.md) for details on:
- ğŸ› Bug reporting
- ğŸ’¡ Feature suggestions
- ğŸ”§ Development setup
- ï¿½ï¿½ Coding standards 
